{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bb9936-f0b0-4152-9a55-8155a50fb8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_28428\\571530455.py:61: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=22050)\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.mp4: \n",
      "[RESULT] Accuracy: 1.0\n",
      "[RESULT] Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "[DONE] Outputs stored in C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import h5py\n",
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\"\n",
    "INPUTS = [\n",
    "    (\"1.mp4\", \"1.txt\"),\n",
    "    (\"2.mp4\", \"2.txt\"),\n",
    "    (\"3.mp4\", \"3.txt\"),\n",
    "    (\"4.mp4\", \"4.txt\"),\n",
    "    (\"5.mp4\", \"5.txt\"),\n",
    "]\n",
    "OUT_H5 = os.path.join(BASE_DIR, \"processed_video.h5\")\n",
    "OUT_SCENE_MODEL = os.path.join(BASE_DIR, \"scene_model.pkl\")\n",
    "OUT_MOOD_MODEL = os.path.join(BASE_DIR, \"mood_model.pkl\")\n",
    "OUT_JSON = os.path.join(BASE_DIR, \"insights.json\")\n",
    "OUT_YAML = os.path.join(BASE_DIR, \"build_metadata.yaml\")\n",
    "VIS_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def extract_video_features(video_path, frame_skip=30):\n",
    "    \"\"\"Extract average color histograms as simple scene features.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if idx % frame_skip == 0:\n",
    "            hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8],\n",
    "                                [0, 256, 0, 256, 0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            frames.append(hist)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def extract_audio_features(video_path):\n",
    "    \"\"\"Extract MFCC audio features.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(video_path, sr=22050)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        return mfcc.mean(axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Audio extraction failed for {video_path}: {e}\")\n",
    "        return np.zeros(13)\n",
    "\n",
    "def extract_text_features(sub_path):\n",
    "    \"\"\"Extract sentiment score from subtitles/text.\"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    try:\n",
    "        with open(sub_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        score = analyzer.polarity_scores(text)\n",
    "        return np.array([score[\"neg\"], score[\"neu\"], score[\"pos\"], score[\"compound\"]])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Text extraction failed for {sub_path}: {e}\")\n",
    "        return np.zeros(4)\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def main():\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Collect features\n",
    "    for vid, sub in INPUTS:\n",
    "        vpath = os.path.join(BASE_DIR, \"archive\", vid)\n",
    "        spath = os.path.join(BASE_DIR, \"archive\", sub)\n",
    "        print(f\"[INFO] Processing {vpath} + {spath}\")\n",
    "\n",
    "        vfeat = extract_video_features(vpath).mean(axis=0)\n",
    "        afeat = extract_audio_features(vpath)\n",
    "        tfeat = extract_text_features(spath)\n",
    "\n",
    "        feat = np.concatenate([vfeat, afeat, tfeat])\n",
    "        all_features.append(feat)\n",
    "\n",
    "        # Fake binary labels for demo (extend later with real mood labels)\n",
    "        all_labels.append(np.random.randint(0, 2))\n",
    "\n",
    "    X = np.array(all_features)\n",
    "    y = np.array(all_labels)\n",
    "\n",
    "    # Save features to HDF5\n",
    "    with h5py.File(OUT_H5, \"w\") as hf:\n",
    "        hf.create_dataset(\"features\", data=X)\n",
    "        hf.create_dataset(\"labels\", data=y)\n",
    "\n",
    "    # Train/test split\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Train pipeline\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500))\n",
    "    ])\n",
    "    pipe.fit(Xtr, ytr)\n",
    "\n",
    "    # Save models\n",
    "    with open(OUT_SCENE_MODEL, \"wb\") as f:\n",
    "        pickle.dump(pipe, f)\n",
    "    with open(OUT_MOOD_MODEL, \"wb\") as f:\n",
    "        pickle.dump(pipe, f)\n",
    "\n",
    "    # Evaluate\n",
    "    ypred = pipe.predict(Xte)\n",
    "    acc = accuracy_score(yte, ypred)\n",
    "    cm = confusion_matrix(yte, ypred)\n",
    "\n",
    "    print(\"[RESULT] Accuracy:\", acc)\n",
    "    print(\"[RESULT] Report:\\n\", classification_report(yte, ypred))\n",
    "\n",
    "    # -------- VISUALS --------\n",
    "    # Accuracy bar\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar([\"Accuracy\"], [acc], color=\"skyblue\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.savefig(os.path.join(VIS_DIR, \"accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix Heatmap\")\n",
    "    plt.savefig(os.path.join(VIS_DIR, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save insights.json\n",
    "    insights = {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"samples\": len(y),\n",
    "        \"label_distribution\": {int(k): int(v) for k, v in zip(*np.unique(y, return_counts=True))}\n",
    "    }\n",
    "    with open(OUT_JSON, \"w\") as f:\n",
    "        json.dump(insights, f, indent=4)\n",
    "\n",
    "    # Save metadata.yaml\n",
    "    metadata = {\n",
    "        \"project\": \"SceneSense\",\n",
    "        \"generated_on\": datetime.now().isoformat(),\n",
    "        \"inputs\": [f\"{v}+{s}\" for v, s in INPUTS],\n",
    "        \"outputs\": {\n",
    "            \"h5\": OUT_H5,\n",
    "            \"scene_model\": OUT_SCENE_MODEL,\n",
    "            \"mood_model\": OUT_MOOD_MODEL,\n",
    "            \"json\": OUT_JSON,\n",
    "            \"yaml\": OUT_YAML,\n",
    "            \"accuracy_plot\": os.path.join(VIS_DIR, \"accuracy.png\"),\n",
    "            \"confusion_matrix\": os.path.join(VIS_DIR, \"confusion_matrix.png\"),\n",
    "        }\n",
    "    }\n",
    "    with open(OUT_YAML, \"w\") as f:\n",
    "        yaml.dump(metadata, f)\n",
    "\n",
    "    print(f\"[DONE] Outputs stored in {BASE_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7a580-8942-4a4f-8572-f1a77308513a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
