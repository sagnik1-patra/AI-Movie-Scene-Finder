{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142b0121-21d5-4df7-8a19-067613113dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_31944\\867333755.py:53: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=22050)\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\2.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\3.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\4.mp4: \n",
      "[INFO] Processing C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.mp4 + C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.txt\n",
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\5.mp4: \n",
      "[DONE] Outputs written to C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import h5py\n",
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\"\n",
    "INPUTS = [\n",
    "    (\"1.mp4\", \"1.txt\"),\n",
    "    (\"2.mp4\", \"2.txt\"),\n",
    "    (\"3.mp4\", \"3.txt\"),\n",
    "    (\"4.mp4\", \"4.txt\"),\n",
    "    (\"5.mp4\", \"5.txt\"),\n",
    "]\n",
    "OUT_H5 = os.path.join(BASE_DIR, \"processed_video.h5\")\n",
    "OUT_SCENE_MODEL = os.path.join(BASE_DIR, \"scene_model.pkl\")\n",
    "OUT_MOOD_MODEL = os.path.join(BASE_DIR, \"mood_model.pkl\")\n",
    "OUT_JSON = os.path.join(BASE_DIR, \"insights.json\")\n",
    "OUT_YAML = os.path.join(BASE_DIR, \"build_metadata.yaml\")\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def extract_video_features(video_path, frame_skip=30):\n",
    "    \"\"\"Extract average color histograms as simple scene features.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if idx % frame_skip == 0:\n",
    "            hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8],\n",
    "                                [0, 256, 0, 256, 0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            frames.append(hist)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def extract_audio_features(video_path):\n",
    "    \"\"\"Extract MFCC audio features.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(video_path, sr=22050)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        return mfcc.mean(axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Audio extraction failed for {video_path}: {e}\")\n",
    "        return np.zeros(13)\n",
    "\n",
    "def extract_text_features(sub_path):\n",
    "    \"\"\"Extract sentiment score from subtitles/text.\"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    try:\n",
    "        with open(sub_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        score = analyzer.polarity_scores(text)\n",
    "        return np.array([score[\"neg\"], score[\"neu\"], score[\"pos\"], score[\"compound\"]])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Text extraction failed for {sub_path}: {e}\")\n",
    "        return np.zeros(4)\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def main():\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []  # dummy labels for training\n",
    "\n",
    "    # Collect features\n",
    "    for vid, sub in INPUTS:\n",
    "        vpath = os.path.join(BASE_DIR, \"archive\", vid)\n",
    "        spath = os.path.join(BASE_DIR, \"archive\", sub)\n",
    "        print(f\"[INFO] Processing {vpath} + {spath}\")\n",
    "\n",
    "        vfeat = extract_video_features(vpath).mean(axis=0)\n",
    "        afeat = extract_audio_features(vpath)\n",
    "        tfeat = extract_text_features(spath)\n",
    "\n",
    "        feat = np.concatenate([vfeat, afeat, tfeat])\n",
    "        all_features.append(feat)\n",
    "        all_labels.append(np.random.randint(0, 2))  # fake labels (0/1)\n",
    "\n",
    "    X = np.array(all_features)\n",
    "    y = np.array(all_labels)\n",
    "\n",
    "    # Save to HDF5\n",
    "    with h5py.File(OUT_H5, \"w\") as hf:\n",
    "        hf.create_dataset(\"features\", data=X)\n",
    "        hf.create_dataset(\"labels\", data=y)\n",
    "\n",
    "    # Train dummy models\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression())\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    with open(OUT_SCENE_MODEL, \"wb\") as f:\n",
    "        pickle.dump(pipe, f)\n",
    "    with open(OUT_MOOD_MODEL, \"wb\") as f:\n",
    "        pickle.dump(pipe, f)\n",
    "\n",
    "    # Save insights.json\n",
    "    insights = {\n",
    "        \"num_videos\": len(INPUTS),\n",
    "        \"feature_shape\": X.shape,\n",
    "        \"label_distribution\": {int(k): int(v) for k, v in zip(*np.unique(y, return_counts=True))}\n",
    "    }\n",
    "    with open(OUT_JSON, \"w\") as f:\n",
    "        json.dump(insights, f, indent=4)\n",
    "\n",
    "    # Save metadata.yaml\n",
    "    metadata = {\n",
    "        \"project\": \"SceneSense\",\n",
    "        \"generated_on\": datetime.now().isoformat(),\n",
    "        \"inputs\": [f\"{v}+{s}\" for v, s in INPUTS],\n",
    "        \"outputs\": {\n",
    "            \"h5\": OUT_H5,\n",
    "            \"scene_model\": OUT_SCENE_MODEL,\n",
    "            \"mood_model\": OUT_MOOD_MODEL,\n",
    "            \"json\": OUT_JSON,\n",
    "            \"yaml\": OUT_YAML\n",
    "        }\n",
    "    }\n",
    "    with open(OUT_YAML, \"w\") as f:\n",
    "        yaml.dump(metadata, f)\n",
    "\n",
    "    print(\"[DONE] Outputs written to\", BASE_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f7902-9491-4892-9046-927821755c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
