{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42fe4b0-96d0-495e-a866-48904fcbb4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Audio extraction failed for C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4: \n",
      "\n",
      "ðŸŽ¬ Video: 1.mp4\n",
      "ðŸ“„ Subtitles: 1.txt\n",
      "ðŸ’¡ Predicted Emotion: Sad (Confidence 0.99)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_13068\\358871974.py:43: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=22050)\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import librosa\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\"\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"mood_model.pkl\")\n",
    "\n",
    "# Map model labels to emotions\n",
    "EMOTION_MAP = {\n",
    "    0: \"Happy\",\n",
    "    1: \"Sad\",\n",
    "    2: \"Tense\",\n",
    "    3: \"Romantic\",\n",
    "    4: \"Action\"\n",
    "}\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def extract_video_features(video_path, frame_skip=30):\n",
    "    \"\"\"Extract average color histogram as video features.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if idx % frame_skip == 0:\n",
    "            hist = cv2.calcHist([frame], [0, 1, 2], None,\n",
    "                                [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            frames.append(hist)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return np.array(frames).mean(axis=0)\n",
    "\n",
    "def extract_audio_features(video_path):\n",
    "    \"\"\"Extract MFCC audio features.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(video_path, sr=22050)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        return mfcc.mean(axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Audio extraction failed for {video_path}: {e}\")\n",
    "        return np.zeros(13)\n",
    "\n",
    "def extract_text_features(text_path):\n",
    "    \"\"\"Extract sentiment features from subtitles/text.\"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    try:\n",
    "        with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        score = analyzer.polarity_scores(text)\n",
    "        return np.array([score[\"neg\"], score[\"neu\"], score[\"pos\"], score[\"compound\"]])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Text extraction failed for {text_path}: {e}\")\n",
    "        return np.zeros(4)\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def predict_emotion(video_path, text_path=None):\n",
    "    # Load trained model\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model not found at {MODEL_PATH}. Run training first.\")\n",
    "    with open(MODEL_PATH, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Extract features\n",
    "    vfeat = extract_video_features(video_path)\n",
    "    afeat = extract_audio_features(video_path)\n",
    "    tfeat = extract_text_features(text_path) if text_path else np.zeros(4)\n",
    "\n",
    "    feat = np.concatenate([vfeat, afeat, tfeat]).reshape(1, -1)\n",
    "\n",
    "    # Predict\n",
    "    pred = int(model.predict(feat)[0])\n",
    "    prob = model.predict_proba(feat)[0].max()\n",
    "\n",
    "    emotion = EMOTION_MAP.get(pred, f\"Label_{pred}\")\n",
    "\n",
    "    print(f\"\\nðŸŽ¬ Video: {os.path.basename(video_path)}\")\n",
    "    if text_path:\n",
    "        print(f\"ðŸ“„ Subtitles: {os.path.basename(text_path)}\")\n",
    "    print(f\"ðŸ’¡ Predicted Emotion: {emotion} (Confidence {prob:.2f})\\n\")\n",
    "\n",
    "    return emotion, prob\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage: change path as needed\n",
    "    video = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.mp4\"\n",
    "    text = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Movie Scene Finder\\archive\\1.txt\"\n",
    "    predict_emotion(video, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bb5ed-dd5f-46d9-a84d-5294127913e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
