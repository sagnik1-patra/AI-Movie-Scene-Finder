ğŸ¬ SceneSense â€” AI Movie Scene Finder & Mood Classifier
ğŸ“Œ Overview

SceneSense is an AI-driven multimodal pipeline that automatically analyzes movies or TV episodes to:

Detect scene boundaries

Classify scene moods/emotions (Happy, Sad, Tense, Romantic, Action)

Generate metadata, insights, and visualizations for search and recommendations

It fuses video, audio, and subtitle text features to deliver scene-level analysis.

âš™ï¸ Features

âœ… Video processing (color histograms, frame-level features)
âœ… Audio feature extraction (MFCCs, energy, tempo)
âœ… Subtitle-based sentiment analysis (VADER)
âœ… Multimodal fusion into a unified feature vector
âœ… Scene-level mood classification
âœ… Export outputs:

SceneSense/
â”‚
â”œâ”€â”€ processed_video.h5     # Saved features & labels
â”œâ”€â”€ scene_model.pkl        # Scene boundary detector (dummy baseline)
â”œâ”€â”€ mood_model.pkl         # Mood classifier model
â”œâ”€â”€ insights.json          # Accuracy, confusion matrix, stats
â”œâ”€â”€ build_metadata.yaml    # Metadata of pipeline run
â”œâ”€â”€ predictions.csv        # Final predictions per video
â””â”€â”€ visuals/               # Graphs and heatmaps
    â”œâ”€â”€ accuracy.png
    â”œâ”€â”€ confusion_matrix.png

ğŸ› ï¸ Tech Stack

Video: OpenCV

Audio: Librosa

Text: VADER Sentiment, HuggingFace (optional extension)

ML: Scikit-learn (Logistic Regression baseline, extendable to deep models)

Visualization: Matplotlib, Seaborn

ğŸ“‚ Dataset / Inputs

The pipeline expects video + subtitle pairs in your archive/ folder. Example:

C:\Users\NXTWAVE\Downloads\AI Movie Scene Finder\archive\
â”‚â”€â”€ 1.mp4
â”‚â”€â”€ 1.txt
â”‚â”€â”€ 2.mp4
â”‚â”€â”€ 2.txt
â”‚â”€â”€ 3.mp4
â”‚â”€â”€ 3.txt
â”‚â”€â”€ 4.mp4
â”‚â”€â”€ 4.txt
â”‚â”€â”€ 5.mp4
â”‚â”€â”€ 5.txt


Each .mp4 file should have a corresponding .txt subtitle/transcript.

ğŸš€ How to Run
1. Install Requirements
pip install opencv-python librosa numpy pandas matplotlib seaborn scikit-learn vaderSentiment h5py pyyaml

2. Train + Evaluate

Run the training + evaluation script:

python scene_sense_eval_plot.py


This will:

Extract features

Train models

Print classification report

Plot accuracy graph & confusion matrix heatmap on screen

3. Make Predictions on All Videos
python scene_sense_predict.py


This generates:

predictions.csv


Example:

video,subtitle,predicted_label,confidence
1.mp4,1.txt,Happy,0.82
2.mp4,2.txt,Sad,0.74
3.mp4,3.txt,Tense,0.68

4. Predict a Single Videoâ€™s Emotion
python scene_sense_single_predict.py


Output:

ğŸ¬ Video: 1.mp4
ğŸ“„ Subtitles: 1.txt
ğŸ’¡ Predicted Emotion: Tense (Confidence 0.78)

ğŸ“Š Outputs & Visuals

Accuracy Graph â†’ shows model accuracy as a bar chart

Confusion Matrix Heatmap â†’ evaluates prediction errors

Predictions.csv â†’ final results with confidence scores
![Confusion Matrix Heatmap](confusion_matrix.png)
ğŸ”® Future Enhancements

Replace dummy Logistic Regression with deep multimodal transformer

Use PySceneDetect for advanced scene boundary detection

Integrate HuggingFace emotion models for richer text analysis

Deploy as an interactive web app (Flask/FastAPI + React/Streamlit)

Add â€œjump-to-sceneâ€ player controls for smart video navigation

ğŸ“ˆ Business Use Cases

Smart video players â†’ â€œjump to happy/tense sceneâ€

Content recommendation engines (Netflix-style)

Film analysis & editing tools

Viewer engagement insights (emotional highs/lows)

ğŸ‘¨â€ğŸ’» Author

Project scaffolding & pipeline setup by Sagnik Patra
GitHub: sagnik1-patra

LinkedIn: linkedin.com/in/sagnik2212
